{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==2.14.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCSd7Ck5qFbf",
        "outputId": "fa271242-0a1e-4a69-bbcc-4227f5679589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras==2.14.0 in /usr/local/lib/python3.10/dist-packages (2.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Bvm9loC-O5K"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data()"
      ],
      "metadata": {
        "id": "sbbTJCLpjP01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5613470-ca4a-4a41-d195-9170ddae7aaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIWdmajgX7wh",
        "outputId": "a845eff0-28d5-44b1-c497-337e9b8ddcaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000 train sequences\n",
            "25000 test sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "viyVZU_jj_cy",
        "outputId": "a25b7aea-064a-42be-f586-58761cfcbd0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 22665, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 21631, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 31050, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the text of reviews is integer-encoded, where each integer represents a specific word in the dictionary."
      ],
      "metadata": {
        "id": "Y2xf4oMRnxaN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decode reviews from index\n"
      ],
      "metadata": {
        "id": "7hRkrx89n1Xo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INDEX_FROM = 3\n",
        "word_index = imdb.get_word_index()\n",
        "word_index = {key:(value+INDEX_FROM) for key,value in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0    # the padding token\n",
        "word_index[\"<START>\"] = 1  # the starting token\n",
        "word_index[\"<UNK>\"] = 2    # the unknown token\n",
        "reverse_word_index = {value:key for key, value in word_index.items()}\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "decode_review(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "rvFp3Vc6X-sK",
        "outputId": "7a63da0d-6537-4118-cccf-a9e52d989d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode_review(X_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "PMHhYRvqYMB4",
        "outputId": "ed4a8438-cd50-4598-e9cb-0ed94a4ae60f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> please give this one a miss br br kristy swanson and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite lacklustre so all you madison fans give this a miss\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "consider the top 15,000 most common words. I will also consider 20% of the training set for validation purpose."
      ],
      "metadata": {
        "id": "m0hligJToWNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 80000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words= vocab_size)\n",
        "\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niJONmPIYOZk",
        "outputId": "bbc96267-01e4-4366-ee0a-0598d75a7319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000 train sequences\n",
            "25000 test sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us inspect how the first review looks like when we only consider the top 5,000 frequent words."
      ],
      "metadata": {
        "id": "rnUE-iTpodjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decode_review(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "2-vcXa1aoZMm",
        "outputId": "d87bb82f-2fa8-435e-d62d-1f80069b6377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert redford's is an amazing actor and now the same being director norman's father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for retail and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also congratulations to the two little boy's that played the part's of norman and paul they were just brilliant children are often left out of the praising list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Truncate and pad the review sequences\n",
        "reviews can be different lengths. We will use the pad_sequences function to standardize the lengths of the reviews.\n",
        "\n"
      ],
      "metadata": {
        "id": "Mjms-5zKoyRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "Gu2MmbPQogEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maximum_sequence_length = 500 # maximum length of all review sequences"
      ],
      "metadata": {
        "id": "n9aJEfE8o3gZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_train, value= word_index[\"<PAD>\"], padding= 'post', maxlen= maximum_sequence_length)\n",
        "X_test = pad_sequences(X_test, value= word_index[\"<PAD>\"], padding= 'post', maxlen= maximum_sequence_length)\n",
        "\n",
        "print('X_train shape:', X_train.shape) # (n_samples, n_timesteps)\n",
        "print('X_test shape:', X_test.shape)"
      ],
      "metadata": {
        "id": "V06dJw9No5UD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "802786b4-afa7-4206-a527-904cb159dfd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (25000, 500)\n",
            "X_test shape: (25000, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0])"
      ],
      "metadata": {
        "id": "C26wV2Zyo8Fv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875b8a49-3fe5-4914-fc66-f5a0dad9de34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    1    14    22    16    43   530   973  1622  1385    65   458  4468\n",
            "    66  3941     4   173    36   256     5    25   100    43   838   112\n",
            "    50   670 22665     9    35   480   284     5   150     4   172   112\n",
            "   167 21631   336   385    39     4   172  4536  1111    17   546    38\n",
            "    13   447     4   192    50    16     6   147  2025    19    14    22\n",
            "     4  1920  4613   469     4    22    71    87    12    16    43   530\n",
            "    38    76    15    13  1247     4    22    17   515    17    12    16\n",
            "   626    18 19193     5    62   386    12     8   316     8   106     5\n",
            "     4  2223  5244    16   480    66  3785    33     4   130    12    16\n",
            "    38   619     5    25   124    51    36   135    48    25  1415    33\n",
            "     6    22    12   215    28    77    52     5    14   407    16    82\n",
            " 10311     8     4   107   117  5952    15   256     4 31050     7  3766\n",
            "     5   723    36    71    43   530   476    26   400   317    46     7\n",
            "     4 12118  1029    13   104    88     4   381    15   297    98    32\n",
            "  2071    56    26   141     6   194  7486    18     4   226    22    21\n",
            "   134   476    26   480     5   144    30  5535    18    51    36    28\n",
            "   224    92    25   104     4   226    65    16    38  1334    88    12\n",
            "    16   283     5    16  4472   113   103    32    15    16  5345    19\n",
            "   178    32     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the model\n",
        "CNN"
      ],
      "metadata": {
        "id": "uMCsjg2vo_8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras\n"
      ],
      "metadata": {
        "id": "gLeF33agpLkQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "519df71d-6641-4d17-ec39-53b56f7c3024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.2.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Dropout, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "4Pxs383qo9yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 16"
      ],
      "metadata": {
        "id": "C4FsSuCopE9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(filters = 64, kernel_size = 3, strides=1, units = 256,\n",
        "                 optimizer='adam', rate = 0.25, kernel_initializer ='glorot_uniform'):\n",
        "  model = Sequential()\n",
        "  # Embedding layer\n",
        "  model.add(Embedding(vocab_size, embedding_dim, input_length= maximum_sequence_length))\n",
        "    # Convolutional Layer(s)\n",
        "  model.add(Dropout(rate))\n",
        "  model.add(Conv1D(filters = filters, kernel_size = kernel_size, strides= strides,\n",
        "                     padding='same', activation= 'relu'))\n",
        "  model.add(GlobalMaxPooling1D())\n",
        "    # Dense layer(s)\n",
        "  model.add(Dense(units = units, activation= 'relu', kernel_initializer= kernel_initializer))\n",
        "  model.add(Dropout(rate))\n",
        "    # Output layer\n",
        "  model.add(Dense(1, activation= 'sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                  optimizer= optimizer,\n",
        "                  metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "bbThMhzstsns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "model = KerasClassifier(build_fn= create_model)"
      ],
      "metadata": {
        "id": "jgJwROS6vZdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_wrapper(filters, kernel_size, strides, units, optimizer, rate, kernel_initializer):\n",
        "    def create_wrapped_model():\n",
        "        return create_model(filters=filters, kernel_size=kernel_size, strides=strides,\n",
        "                            units=units, optimizer=optimizer, rate=rate,\n",
        "                            kernel_initializer=kernel_initializer)\n",
        "    return create_wrapped_model"
      ],
      "metadata": {
        "id": "KxzTAkGlGdpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tune hyperparameters"
      ],
      "metadata": {
        "id": "RibcLxqcvdej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  NOTE: Exhaustive Grid Search Maxes out Colab RAM. To circumvent this bottleneck, we use optuna, a hyperparameter tuning framework."
      ],
      "metadata": {
        "id": "z_N1nmbW45Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### THE COMMENTED OUT PART IS THE CODE FOR EXHAUSTIVE GRID SEARCH"
      ],
      "metadata": {
        "id": "fWC-kWI4oPdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set the hyperparameters\n",
        "# filters = [128] #[64, 128, 256]\n",
        "# kernel_size = [5] #[3, 5, 7]\n",
        "# strides= [1] # [1, 2, 5]\n",
        "# Dense_units = [128, 512]\n",
        "# kernel_initializer = ['TruncatedNormal'] #['zero', 'glorot_uniform', 'glorot_normal','TruncatedNormal']\n",
        "# rate_dropouts = [0.25] #[0.1, 0.25, 0.5]\n",
        "# optimizers = ['adam'] #['adam','rmsprop']\n",
        "# epochs = [5]\n",
        "# batches = [64] #[32, 64, 128]\n",
        "# # ----------------------------------------------\n",
        "# # Exhaustive Grid Search\n",
        "# param_grid = dict(optimizer= optimizers, epochs= epochs, batch_size= batches,\n",
        "#                   filters = filters, kernel_size = kernel_size, strides = strides,\n",
        "#                   units = Dense_units, kernel_initializer= kernel_initializer, rate = rate_dropouts)\n",
        "\n",
        "# grid = ParameterGrid(param_grid)\n",
        "# param_sets = list(grid)\n",
        "\n",
        "# param_scores = []\n",
        "# for params in grid:\n",
        "\n",
        "#     print(params)\n",
        "#     model_params = {k: v for k, v in params.items() if k not in ['epochs', 'batch_size']}\n",
        "#     wrapped_model = model_wrapper(**model_params)\n",
        "\n",
        "#     model = KerasClassifier(build_fn=wrapped_model, epochs=params['epochs'],\n",
        "#                             batch_size=params['batch_size'])\n",
        "\n",
        "#     earlystopper = EarlyStopping(monitor='val_acc', patience= 0, verbose=1)\n",
        "\n",
        "#     model.fit(X_train, y_train, shuffle=True, validation_data=(X_test, y_test), callbacks=[earlystopper])\n",
        "#     history = model.model_.history\n",
        "\n",
        "\n",
        "\n",
        "#     param_score = history.history['val_accuracy']\n",
        "#     param_scores.append(param_score[-1])\n",
        "#     print('+-'*50)\n",
        "#     p = np.argmax(np.array(param_scores))\n",
        "\n",
        "# print('param_scores:', param_scores)\n",
        "# print(\"best score:\", param_scores[p])\n",
        "# # Choose best parameters\n",
        "# best_params = param_sets[p]\n",
        "# print(\"best parameter set\", best_params)"
      ],
      "metadata": {
        "id": "g9OZ_ZFMvadI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def best_model():\n",
        "#     return create_model(filters=best_params['filters'],\n",
        "#                         kernel_size=best_params['kernel_size'],\n",
        "#                         strides=best_params['strides'],\n",
        "#                         units=best_params['units'],\n",
        "#                         optimizer=best_params['optimizer'],\n",
        "#                         rate=best_params['rate'],\n",
        "#                         kernel_initializer=best_params['kernel_initializer'])\n"
      ],
      "metadata": {
        "id": "Ln041edUwp-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize KerasClassifier with the best model\n",
        "# model = KerasClassifier(model=best_model, epochs=best_params['epochs'], batch_size=best_params['batch_size'])\n",
        "\n",
        "# # Fit the model with the combined training and validation sets\n",
        "# model.fit(np.vstack((X_train, X_test)), np.hstack((y_train, y_test)))"
      ],
      "metadata": {
        "id": "3AxBj53RyPYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "55Uf6LanWVBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DVb448VBxwsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vqloUOnOgzwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set the hyperparameters\n",
        "# filters = [64] #[64, 128, 256]\n",
        "# kernel_size = [5] #[3, 5, 7]\n",
        "# strides= [1] # [1, 2, 5]\n",
        "# Dense_units = [128, 512]\n",
        "# kernel_initializer = ['glorot_normal'] #['zero', 'glorot_uniform', 'glorot_normal','TruncatedNormal']\n",
        "# rate_dropouts = [0.25] #[0.1, 0.25, 0.5]\n",
        "# optimizers = ['adam'] #['adam','rmsprop']\n",
        "# epochs = [5]\n",
        "# batches = [64] #[32, 64, 128]\n",
        "# # ----------------------------------------------\n",
        "# # Exhaustive Grid Search\n",
        "# param_grid = dict(optimizer= optimizers, epochs= epochs, batch_size= batches,\n",
        "#                   filters = filters, kernel_size = kernel_size, strides = strides,\n",
        "#                   units = Dense_units, kernel_initializer= kernel_initializer, rate = rate_dropouts)\n",
        "\n",
        "# grid = ParameterGrid(param_grid)\n",
        "# param_sets = list(grid)\n",
        "\n",
        "# param_scores = []\n",
        "# for params in grid:\n",
        "\n",
        "#     print(params)\n",
        "#     model_params = {k: v for k, v in params.items() if k not in ['epochs', 'batch_size']}\n",
        "#     wrapped_model = model_wrapper(**model_params)\n",
        "\n",
        "#     model = KerasClassifier(build_fn=wrapped_model, epochs=params['epochs'],\n",
        "#                             batch_size=params['batch_size'])\n",
        "\n",
        "#     earlystopper = EarlyStopping(monitor='val_acc', patience= 0, verbose=1)\n",
        "\n",
        "#     model.fit(X_train, y_train, shuffle=True, validation_data=(X_test, y_test), callbacks=[earlystopper])\n",
        "#     history = model.model_.history\n",
        "\n",
        "\n",
        "\n",
        "#     param_score = history.history['val_accuracy']\n",
        "#     param_scores.append(param_score[-1])\n",
        "#     print('+-'*50)\n",
        "#     p = np.argmax(np.array(param_scores))\n",
        "\n",
        "# print('param_scores:', param_scores)\n",
        "# print(\"best score:\", param_scores[p])\n",
        "# # Choose best parameters\n",
        "# best_params = param_sets[p]\n",
        "# print(\"best parameter set\", best_params)"
      ],
      "metadata": {
        "id": "bWlgHNwIgzpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def best_model():\n",
        "#     return create_model(filters=best_params['filters'],\n",
        "#                         kernel_size=best_params['kernel_size'],\n",
        "#                         strides=best_params['strides'],\n",
        "#                         units=best_params['units'],\n",
        "#                         optimizer=best_params['optimizer'],\n",
        "#                         rate=best_params['rate'],\n",
        "#                         kernel_initializer=best_params['kernel_initializer'])\n"
      ],
      "metadata": {
        "id": "do1o-sH1gzia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Initialize KerasClassifier with the best model\n",
        "# model = KerasClassifier(model=best_model, epochs=best_params['epochs'], batch_size=best_params['batch_size'])\n",
        "\n",
        "# # Fit the model with the combined training and validation sets\n",
        "# model.fit(np.vstack((X_train, X_test)), np.hstack((y_train, y_test)))"
      ],
      "metadata": {
        "id": "rI2jb3i45W6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTboTgOK_sYm",
        "outputId": "d4478a49-7184-4951-da20-2117856b14f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.6/230.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "optuna.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "RvyDUgYs5W3f",
        "outputId": "ff741b03-fe1f-4a60-b81a-5f3f20ae2f83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.4.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # Suggest hyperparameters\n",
        "    filters = trial.suggest_categorical('filters', [64, 128, 256])\n",
        "    kernel_size = trial.suggest_categorical('kernel_size', [3, 5, 7])\n",
        "    strides = trial.suggest_categorical('strides', [1, 2, 5])\n",
        "    units = trial.suggest_categorical('units', [128, 512])\n",
        "    kernel_initializer = trial.suggest_categorical('kernel_initializer', ['zero', 'glorot_uniform', 'glorot_normal', 'TruncatedNormal'])\n",
        "    rate = trial.suggest_float('rate', 0.1, 0.5)\n",
        "    optimizer = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])\n",
        "    epochs = 5  # Fixed value in your setup\n",
        "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "\n",
        "    # Build and compile model\n",
        "    wrapped_model = model_wrapper(filters, kernel_size, strides, units, optimizer, rate, kernel_initializer)\n",
        "    model = KerasClassifier(build_fn=wrapped_model, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    # Early stopping\n",
        "    earlystopper = EarlyStopping(monitor='val_accuracy', patience=0, verbose=1)\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), callbacks=[earlystopper], verbose=0)\n",
        "    history = model.model_.history\n",
        "\n",
        "    # Retrieve the best validation accuracy\n",
        "    val_accuracy = max(history.history['val_accuracy'])\n",
        "    return val_accuracy\n",
        "\n",
        "# Running the study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=80)  # Adjust the number of trials as needed\n",
        "\n",
        "# Retrieve the best parameters\n",
        "best_params = study.best_params\n",
        "print(\"Best parameters:\", best_params)\n",
        "\n"
      ],
      "metadata": {
        "id": "NQ5IX0rd5W1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the best model\n",
        "def best_model():\n",
        "    return create_model(filters=best_params['filters'],\n",
        "                        kernel_size=best_params['kernel_size'],\n",
        "                        strides=best_params['strides'],\n",
        "                        units=best_params['units'],\n",
        "                        optimizer=best_params['optimizer'],\n",
        "                        rate=best_params['rate'],\n",
        "                        kernel_initializer=best_params['kernel_initializer'])"
      ],
      "metadata": {
        "id": "UPemOlPi5WyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e1i7jk7_5Wvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m0DKe1YR5Wmp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}